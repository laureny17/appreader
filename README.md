# Assignment 3: An AI-Augmented Concept

## Augment the design of a concept: ApplicationAssignments

### Original

```
concept ApplicationAssignments
purpose Store application data (including read-counts) and assign them one at a time to users to read, allowing skips.
principle The admin can add applications to an active event. This should initialize all applications in the database to
    have 0 reads. Each reader is assigned one application to read at a time. Applications are assigned prioritizing
    those with the fewest reads so far, and a user cannot read an application they have already read. Applications can
    be skipped, and get prioritized if so.
state
    a set of CurrentAssignments with
        a User
        an Application
        a startTime DateTime
    a set of Applications with
        an applicantID String
        an applicantYear String
        an answers set of Strings
        a readsCompleted Number
        a readers set of Users
actions
    addApplication (adder: User, event: Event, applicantID: String, applicantYear: String, answers: set of String)
        requires: adder is the Admin and event is an active event
        effect: create applications for each applicantID associated with an applicantYear, a set of answers
            from the application, and initialize readsCompleted = 0 and an empty set of readers
    getNextAssignment (user: User, event: Event, startTime: DateTime): (assignment: CurrentAssignments)
        requires: event is an active event, and user is a reader for event
        effect: create a CurrentAssignment for this user with startTime, with an application
            that does not have user in readers set
```

### AI-Augmented

```
concept ApplicationAssignments
purpose Store application data (including read-counts) and assign them one at a time to users to read, allowing skips.
principle The admin can add applications to an active event. This should initialize all applications in the database to
    have 0 reads and include a set of comments generated by an LLM. Each reader is assigned one application to read at
    a time. Applications are assigned prioritizing those with the fewest reads so far, and a user cannot read an application
    they have already read. Applications can be skipped, and get prioritized if so. The LLM uses question and rubric sets
    of strings passed as parameters to generate AI comments.
state
    a set of CurrentAssignments with
        a User
        an Application
        a startTime DateTime
    a set of Applications with
        an applicantID String
        an applicantYear String
        an answers set of Strings
        a readsCompleted Number
        a readers set of Users
        a set of AIComments
    a set of AIComments with
        a category String
        a quotedSnippet String
        a justification String
actions
    async addApplication (adder: User, event: Event, applicantID: String, applicantYear: String,
    questions: set of String, answers: set of String, rubric: set of String, eligibilityCriteria: set of Strings, llm: GeminiLLM)
        requires: adder is the Admin and event is an active event
        effect: create an application for the event for an applicantID associated with an applicantYear, a set of answers
            from the application, initialize readsCompleted = 0 and an empty set of readers, and and populate AIComments using an
            LLM analysis of the answers that incorporates the provided event questions and rubric, where the category is "Strong," "Weak," or "Attention," the quoted snippet is a substring
            from answers, and the justification is a non-empty string
    getNextAssignment (user: User, event: Event, startTime: DateTime): (assignment: CurrentAssignments)
        requires: event is an active event, and user is a reader for event
        effect: create a CurrentAssignment for this user with startTime, with an application
            that does not have user in readers set
    skipAssignment (user: User, assignment: CurrentAssignments)
        requires: assignment.user = user
        effect: mark the application as skipped by adding user to its readers set, remove CurrentAssignment for user
            so the application can be reassigned to other users but not to this user
    incrementOnSubmit (user: User, assignment: CurrentAssignments)
        requires: assignment.user = user
        effect: increment readsCompleted for the application, add user to readers set, and remove CurrentAssignment for user
```

## Design the user interaction

![AI Augmentation UI Sketches](/public/ai_augmentation_ui.png)

## Implement your concept

[AppReader Repo (you are here!)](https://github.com/laureny17/appreader)

## Explore richer test cases and prompts

[Test Cases](https://github.com/laureny17/appreader/blob/32e8670313ee40b17ea9bcebad066961f623eaf0/tests/application-assignments-tests.ts)

### Prompt 1

```
You are an AI reviewer for an event.
Here are the application questions:
${questions.map((q, i) => `${i + 1}. ${q}`).join("\n")}

Here is the event's rubric:
${rubric.map(r => `- ${r.name}: ${r.description} (scale ${r.scaleMin}-${r.scaleMax})`).join("\n")}

Applicant's answers:
${application.answers.join("\n")}

Analyze each answer and generate comments with categories "Strong", "Weak", or "Attention".
Each comment should include a quoted snippet and a short justification.
Return as a JSON array.
```

This version provided context for the LLM by referencing the questions, rubric, and applicant answers in a conversational setup. It did generate thoughtful and relevant comments, but this prompt caused format issues—the model added text outside the JSON block by including extra commentary. While the responses themselves were fine, the formatting issues meant that we had to create a new prompt.

### Prompt 2

```
You are an AI model that analyzes application answers and returns JSON only.

    Output a JSON array of comments, where each comment object has exactly these keys:
      - "category": one of ["Strong", "Weak", "Attention"]
      - "quotedSnippet": a short substring (<= 2 sentences) directly from the applicant's answers
      - "justification": a one-sentence explanation for the chosen category.

    Do not include any explanations or Markdown formatting outside the JSON.

    Questions:
    ${questions.join("\n")}

    Answers:
    ${application.answers.join("\n")}

    Rubric:
    ${rubric.join("\n")}
    Return only the JSON array — nothing else.
```

This prompt prioritized eliminating the previous issues in order to produce pure JSON. It was effective in eliminating extra commentary, but still retained formatting errors, as it would sometimes wrap the JSON in ```'s. Also, the justification was not always a consistent length, and it also didn't seem completely understand what should be flagged with "Attention." I also realized that if we want Gemini to parse for red flags to flag as "Attention," we should probably provide eligibility requirements as an input to check for.

### Prompt 3

```
You are an AI model that analyzes hackathon application answers and must output STRICT JSON ONLY.

    Return a JSON array of comment objects, where each object has exactly these keys:
      - "category": one of ["Strong", "Weak", "Attention"]
      - "quotedSnippet": a short substring (<= 2 sentences) directly from the applicant's answers
      - "justification": a one-sentence explanation for the chosen category, no longer than 150 characters.

    IMPORTANT RULES:
      - Output ONLY a valid JSON array.
      - Do NOT include Markdown formatting, code fences (\`\`\`), or any text before or after the JSON.
      - The first character in your response must be '[' and the last must be ']'.
      - Classify snippets aligned with desirable traits in the rubric as "Strong"
      - Classify snippets showing a lack of desirable traits in the rubric as "Weak"
      - Classify snippets contradicting previous information written in the application as "Attention".
      - Classify snippets demonstrating disrespect or as "Attention".
      - Classify snippets that contradict or may contract eligibility requirements as "Attention".

    Questions:
    ${questions.join("\n")}

    Answers:
    ${application.answers.join("\n")}

    Eligibility Criteria:
    ${eligibilityCriteria.join("\n")}

    Rubric:
    ${rubric.join("\n")}
```

This final version was designed with clearer, more direct instructions to ensure proper formatting as well as outputs more aligned with the intended output. It explicitly enforced strict JSON formatting rules while also including how to classify responses into the three categories. By incorporating eligibility criteria directly into the prompt, the LLM became better at flagging applicants who did not meet requirements (e.g., “I am a high school student” for an event that requires students to be in college) as “Attention.” This version produced the most consistent results—the JSON formatting was valid, justifications stayed under 150 characters, and category choices aligned with the rubric and eligibility logic.

## Add validators to your code

To validate the LLM's output, I added several validators within the generateAIComments function that check the generated JSON before it’s stored in the application state. (1) One validator ensures that each comment’s "category" field is one of the three allowed values ("Strong", "Weak", or "Attention") by comparing it against a predefined set (validCategories). If the category is invalid, the comment is skipped entirely. (2) The Another validator checks the length of each comment’s "justification" string, ensuring that none of them exceed 150 characters so that comment lengths remain consistent throughout all applications. (3) A third validator detects duplicate "quotedSnippet" entries by maintaining a seenSnippets set and disallowing repeats, ensuring that the LLM doesn't make multiple comments on the same snippet.
